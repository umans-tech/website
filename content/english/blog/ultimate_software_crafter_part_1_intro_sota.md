---
title: "Ultimate Software Crafter - Partie 1 - Agents autonomes de codage, du buzz et des promesses"
meta_title: "Quel est l'√©tat de l'art des agents autonome de d√©veloppement ?"
date: 2024-06-25T22:48:13+02:00
draft: false
author: "Wassel Alazhar"
authors: ["Wassel Alazhar", "Naji Alazhar"]
categories: ["Software Engineering", "AI", "Automation"]
tags: ["LLM", "BENCHMARK", "SWE-Agent", "SWE-bench", "AI", "Automation", "Software Engineering", "Test-Driven Development", "TDD"]
---

> Cet article fait suite √† la pr√©sentation du m√™me titre **Ultimate Software Crafter** que nous (Naji Alazhar et Wassel Alazhar) avons donn√©e le 25 juin 2024 au Meetup Crafting Data Science. [Cette pr√©sentation](https://speakerdeck.com/jcraftsman/the-ultimate-software-crafter-meetup-crafting-data-science) tra√Æte de l'√©tat de l'art des agents autonomes de d√©veloppement logiciel et de leur fonctionnement.

{{< toc >}}

**"Ultimate Software Crafter"**‚Äîun titre qui r√©sonne avec une touche de provocation. L'artisanat logiciel serait-il en voie de disparition ?

Depuis des ann√©es, les d√©veloppeurs s'efforcent de rehausser les standards de leur m√©tier, en cherchant constamment √† allier excellence technique et professionnalisme. Aujourd'hui, avec l'√©mergence des agents autonomes de codage, une question se pose : ces nouvelles technologies menacent-elles cette qu√™te d'am√©lioration continue, ou repr√©sentent-elles une opportunit√© in√©dite ? Avec ces technologies capables de g√©n√©rer du code de mani√®re autonome, quel est encore le r√¥le du d√©veloppeur dans la cr√©ation logicielle ?

Cet article se propose de d√©mystifier ces agents, de d√©cortiquer leur fonctionnement et de r√©fl√©chir √† leur impact potentiel sur notre m√©tier.

Nous explorerons √©galement comment des techniques √©prouv√©es, comme le Test-Driven Development (TDD), peuvent √™tre appliqu√©es √† ces agents pour transformer le d√©veloppement logiciel automatis√©.

Suivez-nous dans cette exploration o√π l'avenir du m√©tier se dessine.

## Un Sujet Br√ªlant

L'agitation autour des agents autonomes de codage est palpable. Les annonces se succ√®dent, aliment√©es par des promesses parfois d√©mesur√©es. [Devin](https://x.com/cognition_labs/status/1767548763134964000), par exemple, s'est fait conna√Ætre comme le "premier ing√©nieur logiciel IA", mais a rapidement [sombr√© dans la controverse](https://x.com/GergelyOrosz/status/1779035184978866332).

Les attentes √©taient √©normes, mais les r√©sultats bien en de√ß√†. D'autres, comme [GitHub Copilot Workspace](https://x.com/github/status/1785006787755721210), n'ont pas √©chapp√© au m√™me sort, accumulant [les d√©mos rat√©es](https://www.youtube.com/watch?v=75Hv0RUFIrQ) qui laissent le public sceptique. Ces agents sont encore en phase de d√©veloppement, loin d'√™tre pr√™ts pour une adoption massive. On nous parle d'une r√©volution imminente, mais jusqu'√† il n'y a pas tr√®s longtemps, seuls des produits ferm√©s et des listes d'attente √©taient disponibles.

Heureusement, des alternatives open-source commencent √† voir le jour, offrant un peu plus de transparence et de compr√©hension. Parmi elles, [SWE-Agent](https://github.com/princeton-nlp/SWE-agent) se distingue, montrant que tout n'est pas qu'une question de marketing. Mais la tendance actuelle ne va pas s'att√©nuer de sit√¥t (avec [des mod√®les LLMs plus performant dans la g√©n√©ration de code](https://x.com/alexalbert__/status/1803804677701869748) et de plus en plus d'[alternatives open-sources avec des approches plus cr√©dibles](https://www.tiktok.com/@steve8708/video/7382315491341126955)). Les d√©bats autour de ces technologies, entre espoir et d√©sillusion, continuent d'alimenter la conversation. Dans ce contexte bouillonnant, il devient crucial de d√©m√™ler le vrai du faux et d'explorer ce dont ces agents sont vraiment capables.

<!-- markdownlint-disable MD033 -->

<div style="display: flex; justify-content: space-between; flex-wrap: wrap; gap: 10px; max-width: 100%; margin: 0 auto;">
  <div style="flex: 1; min-width: 300px; max-width: 42%;">
    <blockquote class="twitter-tweet" data-dnt="true">
      <p lang="en" dir="ltr">
        Today we&#39;re excited to introduce Devin, the first AI software engineer.<br><br>
        Devin is the new state-of-the-art on the SWE-Bench coding benchmark, has successfully passed practical engineering interviews from leading AI companies, and has even completed real jobs on Upwork‚Ä¶ <a href="https://t.co/ladBicxEat">pic.twitter.com/ladBicxEat</a>
      </p>
      &mdash; Cognition (@cognition_labs)
      <a href="https://twitter.com/cognition_labs/status/1767548763134964000?ref_src=twsrc%5Etfw">March 12, 2024</a>
    </blockquote>
    <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
  </div>

  <div style="flex: 1; min-width: 300px; max-width: 42%;">
    <blockquote class="twitter-tweet">
      <p lang="en" dir="ltr">
        Devin (named ‚Äúthe world‚Äôs first AI engineer‚Äù from the start) and looked to me it‚Äôs far more marketing and hype than reality.<br><br>
        But even I didn‚Äôt assume how their own staged video would blatantly lie. It does. A software engineer looked closer. Damning:
        <a href="https://t.co/iKu8yfuFbA">https://t.co/iKu8yfuFbA</a>
      </p>
      &mdash; Gergely Orosz (@GergelyOrosz)
      <a href="https://twitter.com/GergelyOrosz/status/1779035184978866332?ref_src=twsrc%5Etfw">April 13, 2024</a>
    </blockquote>
    <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
  </div>
</div>

<!-- markdownlint-enable MD033 -->

Nous entrerons maintenant dans le vif du sujet en analysant les capacit√©s actuelles des agents de codage autonomes. Que peuvent-ils r√©ellement accomplir ?

## Quelles sont les capacit√©s actuelles des agents de codage ? √âtat de l'art

Quand nous parlons d'agent autonome de codage, nous faisons r√©f√©rence √† un programme capable de r√©soudre une t√¢che en toute autonomie et de soumettre une Pull Request (PR) √† partir d'une demande de changement (issue, t√¢che, ou User Story) fournie sous forme de texte ou provenant d'un outil de gestion comme GitHub Issues, Jira, ou Notion.

R√©pondre √† la question "Quelles sont les capacit√©s actuelles des agents de codage ?" est cependant complexe pour plusieurs raisons. Les performances de ces agents varient consid√©rablement en fonction des t√¢ches, des environnements, et des mod√®les sous-jacents utilis√©s. De plus, les benchmarks et les √©tudes montrent des r√©sultats en constante √©volution, rendant difficile une √©valuation stable. Enfin, les contextes d'application, les types de probl√®mes r√©solus et la mani√®re dont ces agents sont int√©gr√©s aux processus existants influencent √©galement leurs capacit√©s r√©elles.

Pour tenter de r√©pondre √† cette question, nous nous appuyons sur deux √©tudes r√©centes qui, malgr√© quelques limites et biais, restent parmi les sources les plus s√©rieuses disponibles :

1. **SWE-Agent: Agent-Computer Interfaces Enable Automated Software Engineering** ([Lire sur arXiv](https://arxiv.org/abs/2405.15793))
2. **SWE-bench: Can Language Models Resolve Real-World GitHub Issues?** ([Lire sur arXiv](https://arxiv.org/abs/2310.06770))

### Benchmarking et r√©sultats

SWE-bench est une r√©f√©rence pour √©valuer les performances des agents de codage. Le protocole est rigoureux : l'agent re√ßoit le commit parent d'une PR r√©solue et doit proposer une nouvelle PR qui sera valid√©e en ex√©cutant tous les tests associ√©s. Ce processus permet de v√©rifier la capacit√© de l'agent √† r√©soudre les probl√®mes de mani√®re autonome, sans engendrer de r√©gressions.

![SWE-bench, benchmarking protocol](/images/blog/swe-bench-protocol.png)

**SWE-bench Full** Ce dataset contient 2294 t√¢ches √† r√©soudre (GitHub issues) s√©lection√©es depuis 12 des d√©p√¥ts GitHub python les plus populaires (Django, flask, matplotlib, requests, scikit learn, sympy‚Ä¶). Les repos cibl√©s r√©pondaient aux crit√®res suivants : des guidelines de contrinutions claires, une bonne couverture de tests, globalement bien maintenu (avec des commits r√©guliers).

**SWE-bench Lite** est un dataset all√©g√©, con√ßu pour se concentrer sur des issues plus cibl√©es et √©liminer les variables qui pourraient biaiser les r√©sultats. Cette version exclut, entre autres, les issues avec des d√©pendances externes ou des images, celles dont la description est trop courte (moins de 40 mots), ainsi que les PR touchant √† plusieurs fichiers. Avec 300 issues s√©lectionn√©es pour leur clart√© et leur maintenabilit√©, SWE-bench Lite fournit un cadre plus pr√©cis (et surtout plus √©conomique) pour √©valuer la performance des agents dans un environnement contr√¥l√©.

![SWE-bench, The evolution of agent's issues resolution performance](/images/blog/swe-bench-evolution.png)

Les r√©sultats obtenus peuvent impressionner, mais ils doivent √™tre interpr√©t√©s avec pr√©caution. L'√©volution rapide des performances, comme illustr√© dans le graphique ci-dessus, montre une am√©lioration continue des taux de r√©solution. Cependant, tous les r√©sultats ne sont pas toujours comparables. Par exemple, AutoCodeRover avec GPT-4 a atteint 19 % de r√©ussite, mais cela inclut trois ex√©cutions distinctes (Pass@3) et le temps de r√©solution est bien plus lent que d'autres agents.

Dans cet environnement de donn√©es souvent complexes, nous recommandons de se concentrer sur des r√©sultats transparents et v√©rifi√©s, notamment ceux obtenus en open-source, avec une seule ex√©cution (Pass@1). √Ä ce jour, ces taux atteignent 18,13 % pour le benchmark standard et 26,67 % pour SWE-bench Lite.

> OpenAI s'est √©galement int√©ress√© √† ce domaine, proposant [SWE-bench Verified](https://openai.com/index/introducing-swe-bench-verified/), un ensemble de 500 probl√®mes valid√©s par des ing√©nieurs logiciels, offrant ainsi un cadre d'√©valuation encore plus rigoureux.

### Limitations et Opportunit√©s

#### Limitations

Les agents actuels montrent des lacunes lorsqu'ils doivent traiter des issues n√©cessitant peu de modifications ou lorsque les descriptions sont trop concises. De plus, notre analyse se concentre uniquement sur la phase allant de l'issue √† la PR, excluant ainsi :

- Le travail apr√®s la PR (revue, tests, d√©ploiement, monitoring‚Ä¶)
- Le travail avant l'issue (discussions, formulation des besoins‚Ä¶)

#### Opportunit√©s üöß

Malgr√© ces limitations, les agents autonomes pr√©sentent un potentiel √©conomique int√©ressant :

- **149,58 jours-homme pour 600 $**, contre 75 000 $ en m√©thode traditionnelle.

D√©tails :

- Co√ªt : < 2 $ par issue (API GPT-4o) + infrastructure d'ex√©cution.
- R√©sultats : 54 issues r√©solues sur 300, soit 149,58 jours-homme.
- Co√ªt moyen par jour-homme : 4,01 $.

Les r√©sultats pour SWE-bench Lite sont encore plus impressionnants :

- **221,63 jours-homme pour 50 $**, contre 111 000 $ en m√©thode traditionnelle.

### Potentiel d'am√©lioration

#### Ex√©cutions multiples

Les taux de r√©ussite peuvent √™tre am√©lior√©s en multipliant les tentatives. Comme le montre le Pass@k, plusieurs ex√©cutions d'une m√™me issue peuvent significativement augmenter les performances globales.

#### Am√©lioration de la qualit√© du feedback

Un autre levier d'am√©lioration r√©side dans la qualit√© du feedback fourni √† l'agent pendant la r√©solution des issues. En int√©grant une approche "test-first", nous pensons que ces taux de r√©ussite pourraient encore augmenter. Le feedback en continu permettrait √† l'agent de corriger ses erreurs plus efficacement, am√©liorant ainsi la qualit√© et la pertinence des PR g√©n√©r√©es.

### Vers une compr√©hension plus approfondie : Comment fonctionnent r√©ellement les agents de codage ?

Les capacit√©s actuelles des agents de codage ouvrent de nouvelles perspectives pour l'automatisation de l'ing√©nierie logicielle, mais elles soul√®vent aussi des questions sur la mani√®re dont ces technologies s'int√®grent dans nos pratiques existantes. Pour approfondir notre exploration, nous allons maintenant examiner comment ces agents fonctionnent en d√©tail et comment ils peuvent √™tre optimis√©s pour un impact maximal.
