---
title: "Ultimate Software Crafter"
date: 2024-06-25T22:48:13+02:00
draft: false
authors: Wassel Alazhar, Naji Alazhar
---

**"Ultimate Software Crafter"**‚Äîun titre qui r√©sonne avec une touche de provocation. L'artisanat logiciel serait-il en voie de disparition ?

Depuis des ann√©es, les d√©veloppeurs s'efforcent de rehausser les standards de leur m√©tier, en cherchant constamment √† allier excellence technique et professionnalisme. Aujourd'hui, avec l'√©mergence des agents autonomes de codage, une question se pose : ces nouvelles technologies menacent-elles cette qu√™te d'am√©lioration continue, ou repr√©sentent-elles une opportunit√© in√©dite ? Avec ces technologies capables de g√©n√©rer du code de mani√®re autonome, quel est encore le r√¥le du d√©veloppeur dans la cr√©ation logicielle ?

Cet article se propose de d√©mystifier ces agents, de d√©cortiquer leur fonctionnement et de r√©fl√©chir √† leur impact potentiel sur notre m√©tier.

Nous explorerons √©galement comment des techniques √©prouv√©es, comme le Test-Driven Development (TDD), peuvent √™tre appliqu√©es √† ces agents pour transformer le d√©veloppement logiciel automatis√©.

Suivez-nous dans cette exploration o√π l'avenir du m√©tier se dessine.

## Un Sujet Br√ªlant

L'agitation autour des agents autonomes de codage est palpable. Les annonces se succ√®dent, aliment√©es par des promesses parfois d√©mesur√©es. Devin, par exemple, s'est fait conna√Ætre comme le "premier ing√©nieur logiciel IA", mais a rapidement sombr√© dans la controverse. Les attentes √©taient √©normes, mais les r√©sultats bien en de√ß√†. D'autres, comme GitHub Copilot Workspace, n'ont pas √©chapp√© au m√™me sort, accumulant les d√©mos rat√©es qui laissent le public sceptique. Ces agents sont encore en phase de d√©veloppement, loin d'√™tre pr√™ts pour une adoption massive. On nous parle d'une r√©volution imminente, mais pour l'instant, seuls des produits ferm√©s et des listes d'attente sont disponibles.

Heureusement, des alternatives open-source commencent √† voir le jour, offrant un peu plus de transparence et de compr√©hension. Parmi elles, SWE-Agent se distingue, montrant que tout n'est pas qu'une question de marketing. Mais la tendance actuelle ne va pas s'att√©nuer de sit√¥t. Les d√©bats autour de ces technologies, entre espoir et d√©sillusion, continuent d'alimenter la conversation. Dans ce contexte bouillonnant, il devient crucial de d√©m√™ler le vrai du faux et d'explorer ce dont ces agents sont vraiment capables.

Nous entrerons maintenant dans le vif du sujet en analysant les capacit√©s actuelles des agents de codage autonomes. Que peuvent-ils r√©ellement accomplir ?

## Quelles sont les capacit√©s actuelles des agents de codage ? √âtat de l'art

La r√©ponse √† cette question n'est pas simple
Mais le mieux qu'on a trouv√© pour r√©pondre √† cette question sont :

1. **SWE-Agent: Agent-Computer Interfaces Enable Automated Software Engineering** - [Lire sur arXiv](https://arxiv.org/abs/2405.15793)
2. **SWE-Bench: Can Language Models Resolve Real-World GitHub Issues?** - [Lire sur arXiv](https://arxiv.org/abs/2310.06770)

### Examen des capacit√©s actuelles des agents de codage, au-del√† du battage m√©diatique

Dans cette partie on va s'int√©resser aux agents de codage qui ont la capacit√© de soumettre en toute autonomie une PR √† partir d'une demande de changement (issue / t√¢che / US) du texte qu'on donne √† l'agent ou auquel il peut y acc√©der depuis un outil de ticketing (comme github issue par exemple, ou Jira ou Notion...)

### Pr√©sentation du benchmark SWE-Bench et de ses r√©sultats, y compris les taux de r√©solution des probl√®mes par les agents

Expliquer le protocol de SWE-BENCH [√† partir du papier](https://arxiv.org/abs/2310.06770)

Annoncer les r√©sultats

2 remarques principales :

- √áa va vite, tr√®s vite. Illustrer par un graphe avec le max des taux √† chaque date
- M√©fiez-vous des r√©sultats publi√©s dans le leaderboard. On a v√©rifi√© quelques un et on a trouv√© que les r√©sultats publi√©s sont trompeurs. Par exemple, les 19% annonc√© de "ü§† AutoCodeRover (v20240408) + GPT 4 (0125)" sont issue des r√©sultats aggr√©g√©s de 3 executions (Pass@3) en plus il est trop lent par rapport √† SWE-agent. On expliquera plus tard l'impact, l'int√©r√™t et les challenges d'aggr√©ger les r√©sultats de plusieurs executions.

Pour l'instant, dans un climat o√π il est difficile de voir clair, notre recommendation c'est de ne s'int√©resser dans ce leaderboard qu'aux r√©sultats qui cochent toutes les cases (open source pour la transparence, v√©rifi√©s et le taux concerne une seul execution Pass @1)
avec √ßa on arrive √†  18.13% aujourdh'hui (13% au moment quand nous avons fait notre pr√©sentaiton la premi√®re fois le 25/06/2024) et 26.67% pour le dataset bench-lite.

Expliquer la diff√©rence entre SWE-BENCH et [SWE-BENCH lite](https://www.swebench.com/lite.html)

### Opportunit√©s et limitations observ√©es avec l'utilisation des agents dans l'automatisation de l'ing√©nierie logicielle

#### Limitations

Dans l'√©tat, les agents ne savent pas encore r√©soudre :

- Issues that don't require many changes
- The issue description is concise and self-contained
Dans cette √©tude on focalise sur travail entre l'issue et la PR, c√†d la partie du travail du d√©veloppeur qui une fois le besoin du changement est formul√© et l√©criture du code c√†d avant sa revue et sonint√©gration de ce changement √† la base principale ce qui exclue :
- Work after the PR (review, test, release, monitor...)
- Work before the issue (conversation, formulation...)

#### Opportunit√©s

D√©j√† dans l'√©tat, on pourrait pensait qu'il aurait un int√©r√™t √©conomique;
Si on se met dans la peau d'un d√©cideur, on pourrait √™tre facilement tent√© par l'id√©e avec ce calcul approximatif :

149.58 man day
for 600$
instead of 75K$*

(*) assuming 500$ average daily rate

D√©tail du calcul :
Cost:

- < 2$ per issue (Gpt-4o LLM api)
- few $ for the agent execution infrastructure
- 300 issue => ~600$
Expected benefits:
- 54 / 300 issues solved
- 2.77 man day / issue (avg)
- 18% *2.77* 300 = 149.58 man days
- (300 * 2$) / 149.58 = 4.01 $ cost per man day
- 2-10 min / issue

‚ÄúIt costs on average ~2.77 days for developers to create pull requests‚Ä¶‚Äù [samples from SWE-Bench-Lite dataset]
Source: ‚ÄúAutoCodeRover: Autonomous Program Improvement‚Äù paper. <https://arxiv.org/pdf/2404.05427>

Et pour 26.67%

221.63 man day
for 50$
instead of 111K$*

d√©tail du calcul :
Cost :

- 0.15 $ per issue (Sonnet 3.5 LLM api)
- few $ for the agent execution infrastructure
- 300 issue => ~50$
Expected benefits:
- 2.77 man day / issue (avg)
- 26.67% *2.77* 300 = 221.63 man days
- 50$ / 221.63 ~ 0.23 $ cost per man day
- 2-10 min / issue

#### Potentiel d'am√©lioration gr√¢ce aux executions multiples

En r√©alit√©, ces taux peuvent √™tre am√©lior√©s de mani√®re sygnificative sans am√©liorer l'agent ou le mod√®le qu'il y a derri√®re. Il suffit de relancer plusieurs fois (et l√† on explique l'impact du Pass@k) qu'on avait introduit avant en citant la source ci-dessous

Extrait de <https://arxiv.org/pdf/2405.15793> :
B.5 Performance Variance and Pass@k Rate
Since running SWE-agent on SWE-bench can be rather expensive, we perform, all results, unless
otherwise stated, are reported using a pass@1 metric (% Resolved). However, we also test our main
SWE-agent configuration for a higher number of runs to test the variance and pass@k performance
for k ‚àà {3, 6}. These results are shown in Table 10, suggesting that average performance variance is
relatively low, though per-instance resolution can change considerably.
Table 10: Performance for 6 separate runs of SWE-agent with GPT-4 on SWE-bench Lite. The %
Resolved rate for each individual run is shown in the first table, and the pass@k rate in the second.
SWE-bench Lite
Run 1 Run 2 Run 3 Run 4 Run 5 Run 6 Avg.
Resolve % 17.33 18.00 18.00 18.67 17.33 18.33 17.940.49
Pass@1 Pass@2 Pass@3 Pass@4 Pass@5 Pass@6
Pass@k 17.94 23.89 27.35 29.67 31.33 32.67

#### Potentiel d'am√©lioration en am√©liorant la qualit√© du feedback dont dispose l'agent pendant la r√©solution

En r√©alit√© nous pensons, que ce taux peux √™tre encore am√©lior√© en l'√©tat

## D√©monstration en Direct (## Live Demo)

- Description d√©taill√©e de la d√©monstration en direct pr√©sent√©e dans le talk.
- Explication des concepts de base des agents autonomes et de leur fonctionnement.
- Analyse de la performance des agents en utilisant une approche "Test-First".

issue marshmallow:

- D√©mo avec swe-agent gpt-4o en tdd
- puis swe-agent deepseek-coder v2 en TDD
- puis avec Gitlab-ci

## Comment Fonctionnent les Agents de codage ?

(Alternative de titre : ## Comment √ßa marche un agent autonome de d√©veloppement ?)

- Exploration des principes de base des agents autonomes.
- Analyse des principales conclusions sur leur fonctionnement, y compris l'importance des d√©mos et des exemples.
- Discussion sur les d√©fis et les solutions pour am√©liorer la performance des agents.

## L'Impact de l'Approche "Test-First"

- Discussion sur comment l'approche "Test-First" am√©liore la performance des agents.
- Importance des cycles de r√©troaction pour corriger les erreurs et am√©liorer les r√©sultats des agents.
- Perspectives sur l'avenir de l'ing√©nierie logicielle automatis√©e avec une adoption plus large de TDD (Test-Driven Development).

## D√©fis Principaux et Directions Futures

- Identification des principaux d√©fis li√©s aux mod√®les, au contexte, aux co√ªts et aux donn√©es.
- Exploration des futures directions, y compris l'am√©lioration des interfaces d'agents et l'int√©gration avec des syst√®mes de surveillance et de gestion des exceptions en temps r√©el.

## Conclusion et Appel √† la Discussion

(Alternative de titre : ## Et apr√®s ? Discutons-en !)

- Synth√®se des points abord√©s dans la pr√©sentation.
- Invitation √† discuter des implications de ces innovations pour l'avenir de l'ing√©nierie logicielle.

## R√©f√©rences

### Publications acad√©miques et articles

1. **SWE-Agent: Agent-Computer Interfaces Enable Automated Software Engineering** - [Lire sur arXiv](https://arxiv.org/abs/2405.15793)
2. **SWE-Bench: Can Language Models Resolve Real-World GitHub Issues?** - [Lire sur arXiv](https://arxiv.org/abs/2310.06770)
3. **AutoCodeRover: Autonomous Program Improvement** - [Lire sur arXiv](https://arxiv.org/pdf/2404.05427)
4. **Canon TDD, by Kent Beck** - [Lire sur Tidy First](https://tidyfirst.substack.com/p/canon-tdd)
5. **ReAct: Synergizing Reasoning and Acting in Language Models** - [Lire sur arXiv](https://arxiv.org/abs/2210.03629)
6. **Applying Generative AI to CVE remediation ‚Äì early vulnerability patching in Continuous Integration Pipelines** - [Lire l'article](https://aws.amazon.com/fr/blogs/containers/applying-generative-ai-to-cve-remediation-early-vulnerability-patching-in-continuous-integration-pipelines/)
7. **Map Evolution not Maturity, by Simon Wardley** - [Lire sur Medium](https://medium.com/@swardley/map-evolution-not-maturity-bae6ea1a2743)
8. **Wardley Maps, by Simon Wardley** - [T√©l√©charger le PDF](https://coach-agile.com/wp-content/uploads/2022/09/Wardley-Maps-Simon-Wardley-compresse.pdf)
9. **Clean Code, Robert C. Martin (2008)** - Citation : "One might argue that a book about code is somehow behind the times that code is no longer the issue; that we should be concerned about models and requirements instead."

### Liens, tweets et vid√©os (par ordre d'apparition)

1. **Debunking Devin: "First AI Software Engineer" Upwork lie exposed!** - [YouTube](https://www.youtube.com/watch?v=tNmgmwEtoWE)
2. **Analyse critique de Devin par Gergely Orosz** - [Twitter](https://twitter.com/GergelyOrosz/status/1779035184978866332)
3. **Annonce de GitHub Copilot Workspace** - [Twitter](https://x.com/github/status/1785006787755721210)
4. **Vid√©o YouTube sur les d√©mos rat√©es de GitHub Copilot** - [YouTube](https://www.youtube.com/watch?v=75Hv0RUFIrQ)
5. **Vid√©o TikTok sur l'approche Test-First utilis√©e par Micro Agent** - [TikTok](https://www.tiktok.com/@steve8708/video/7382315491341126955)
6. **Tweet d'Alex Albert sur la tendance du code g√©n√©r√© par LLMs** - [Twitter](https://x.com/alexalbert__/status/1803804677701869748)
7. **Alberto Brandolini sur l'importance de la compr√©hension des d√©veloppeurs** - [Twitter](https://twitter.com/ziobrando)
8. **Gregor Hohpe sur les probl√®mes inutiles en informatique d'entreprise** - [Twitter](https://x.com/ghohpe/status/1782429303948583284)
9. **Derek Comartin sur les d√©veloppeurs et les goulots d'√©tranglement du codage** - [Twitter](https://x.com/codeopinion/status/1601987262559944705)
10. **Pr√©sentation "Le vieux monde se meurt, le nouveau monde tarde √† appara√Ætre, et dans ce clair-obscur surgissent les monstres" par Arnaud Lemaire** - [Speaker Deck](https://speakerdeck.com/lilobase/le-vieux-monde-se-meurt-le-nouveau-monde-tarde-a-apparaitre-et-dans-ce-clair-obscur-surgissent-les-monstres-agile-pays-basque-2019?slide=107)
11. **Kent Beck sur l'impact des cycles de feedback** - [Twitter](https://x.com/KentBeck/status/1148263160006107136)

### Repositories de code li√©s √† SWE-Agent et micro-agent

- **SWE-Agent sur GitHub** - [Princeton NLP](https://github.com/princeton-nlp/SWE-agent)
- **Micro-Agent sur GitHub** - [BuilderIO](https://github.com/BuilderIO/micro-agent)
